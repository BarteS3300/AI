{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\barte\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': ['question_id', 'parent_answer_post_id', 'prob', 'snippet', 'intent', 'rewritten_intent', 'id']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1782/1782 [00:01<00:00, 1487.86 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 198/198 [00:00<00:00, 1379.63 examples/s]\n",
      "C:\\Users\\barte\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|â–‹         | 30/446 [00:39<10:23,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6864, 'grad_norm': 0.14232756197452545, 'learning_rate': 0.0018744394618834081, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|â–ˆâ–Ž        | 60/446 [01:33<11:45,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2694, 'grad_norm': 0.11841235309839249, 'learning_rate': 0.0017399103139013453, 'epoch': 0.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 90/446 [02:59<28:41,  4.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2641, 'grad_norm': 0.10743214190006256, 'learning_rate': 0.0016053811659192826, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|â–ˆâ–ˆâ–‹       | 120/446 [04:39<16:40,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2465, 'grad_norm': 0.16799403727054596, 'learning_rate': 0.0014708520179372198, 'epoch': 0.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 150/446 [05:31<06:32,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1845, 'grad_norm': 0.10975343734025955, 'learning_rate': 0.001336322869955157, 'epoch': 0.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 180/446 [06:11<05:47,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1997, 'grad_norm': 0.13838952779769897, 'learning_rate': 0.0012017937219730942, 'epoch': 0.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 210/446 [06:45<03:51,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2075, 'grad_norm': 0.11344566196203232, 'learning_rate': 0.0010672645739910314, 'epoch': 0.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 223/446 [07:02<03:59,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1906210333108902, 'eval_runtime': 3.7564, 'eval_samples_per_second': 52.71, 'eval_steps_per_second': 6.655, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 240/446 [07:49<09:22,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1844, 'grad_norm': 0.07202663272619247, 'learning_rate': 0.0009327354260089686, 'epoch': 1.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 270/446 [09:21<08:48,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1567, 'grad_norm': 0.11686361581087112, 'learning_rate': 0.0007982062780269058, 'epoch': 1.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 300/446 [10:14<04:16,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1657, 'grad_norm': 0.08004018664360046, 'learning_rate': 0.000663677130044843, 'epoch': 1.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 330/446 [11:10<05:11,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1576, 'grad_norm': 0.16956141591072083, 'learning_rate': 0.0005291479820627803, 'epoch': 1.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 360/446 [12:35<04:11,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1874, 'grad_norm': 0.11554933339357376, 'learning_rate': 0.0003946188340807175, 'epoch': 1.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 390/446 [14:02<02:38,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2097, 'grad_norm': 0.14716693758964539, 'learning_rate': 0.0002600896860986547, 'epoch': 1.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 420/446 [16:24<02:59,  6.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1741, 'grad_norm': 0.06998071074485779, 'learning_rate': 0.00012556053811659193, 'epoch': 1.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 446/446 [17:54<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.17699161171913147, 'eval_runtime': 5.1608, 'eval_samples_per_second': 38.366, 'eval_steps_per_second': 4.844, 'epoch': 2.0}\n",
      "{'train_runtime': 1074.5677, 'train_samples_per_second': 3.317, 'train_steps_per_second': 0.415, 'train_loss': 0.3011160944609364, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_loss': 0.17699161171913147, 'eval_runtime': 5.082, 'eval_samples_per_second': 38.961, 'eval_steps_per_second': 4.919, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./p3Tokenizer\\\\tokenizer_config.json',\n",
       " './p3Tokenizer\\\\special_tokens_map.json',\n",
       " './p3Tokenizer\\\\spiece.model',\n",
       " './p3Tokenizer\\\\added_tokens.json')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model_name = \"t5-small\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"codeparrot/conala-mined-curated\")\n",
    "print(dataset.column_names)\n",
    "\n",
    "# Preprocess the dataset\n",
    "def tokenize_function(examples):\n",
    "    inputs = tokenizer([\"translate English to Python: \" + doc for doc in examples[\"rewritten_intent\"]], truncation=True, padding=\"max_length\", max_length=512)\n",
    "    labels = tokenizer(examples[\"snippet\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "    inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return inputs\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "dataset = dataset['train'].train_test_split(test_size=0.1)\n",
    "train_dataset = dataset['train'].shard(index=0, num_shards=300)\n",
    "validation_dataset = dataset['test'].shard(index=0, num_shards=300)\n",
    "\n",
    "# Tokenize the datasets\n",
    "tokenized_train_datasets = train_dataset.map(tokenize_function, batched=True, batch_size=1000)\n",
    "tokenized_validation_datasets = validation_dataset.map(tokenize_function, batched=True, batch_size=1000)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=30,\n",
    "    fp16=True,  # Enable mixed precision training\n",
    ")\n",
    "\n",
    "# Move model to GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "    print(\"Using GPU!\")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_datasets,\n",
    "    eval_dataset=tokenized_validation_datasets,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "eval_result = trainer.evaluate()\n",
    "print(f\"Evaluation results: {eval_result}\")\n",
    "\n",
    "# Save the model and tokenizer\n",
    "model.save_pretrained(\"./p3Model\")\n",
    "tokenizer.save_pretrained(\"./p3Tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved model to GPU\n",
      "Generated code: def __init__(list): if __init__(list): pass\n",
      "Generated code: append(python)\n",
      "Generated code: def remove element from a list by value\n",
      "Generated code: for i in range(items): if items[items[items[items[items[items[items[items[items[items[items[items[items[items[items[items[items[items[items][items[items[items[items[items][i]]): i in range(items): pass\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"./p3Model\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"./p3Tokenizer\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "    print(\"Moved model to GPU\")\n",
    "\n",
    "def generate_code(model, tokenizer, text):\n",
    "    # Preprocess the text\n",
    "    inputs = tokenizer.encode(text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    # Move inputs to GPU if available\n",
    "    if torch.cuda.is_available():\n",
    "        inputs = inputs.cuda()\n",
    "    # Generate code\n",
    "    code_ids = model.generate(inputs, max_length=256, num_beams=4, early_stopping=True)\n",
    "    # Decode the code\n",
    "    code = tokenizer.decode(code_ids[0], skip_special_tokens=True)\n",
    "    return code\n",
    "\n",
    "# Example text input\n",
    "text_inputs = [\"converting integer to list\",\n",
    "                \"append to a list python\",\n",
    "                \"remove element from a list by value\",\n",
    "                \"get numpy array\",]\n",
    "for text_input in text_inputs:\n",
    "    generated_code = generate_code(model, tokenizer, text_input)\n",
    "    print(f\"Generated code: {generated_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': ['question_id', 'parent_answer_post_id', 'prob', 'snippet', 'intent', 'rewritten_intent', 'id']}\n",
      "{'question_id': 34705205, 'parent_answer_post_id': 34705233, 'prob': 0.8690001442846342, 'snippet': 'sorted(l, key=lambda x: (-int(x[1]), x[0]))', 'intent': 'Sort a nested list by two elements', 'rewritten_intent': \"sort a nested list l by two elements '1' and '0'\", 'id': '34705205_34705233_0'}\n",
      "{'question_id': 13905936, 'parent_answer_post_id': 13905946, 'prob': 0.8526701436370034, 'snippet': '[int(x) for x in str(num)]', 'intent': 'converting integer to list in python', 'rewritten_intent': 'convert integer num to list', 'id': '13905936_13905946_0'}\n",
      "{'question_id': 13837848, 'parent_answer_post_id': 13838041, 'prob': 0.8521431843789492, 'snippet': \"c.decode('unicode_escape')\", 'intent': 'Converting byte string in unicode string', 'rewritten_intent': 'convert byte string c to unicode string', 'id': '13837848_13838041_0'}\n",
      "{'question_id': 23490152, 'parent_answer_post_id': 23490179, 'prob': 0.850829261966626, 'snippet': \"parser.add_argument('-t', dest='table', help='', nargs='+')\", 'intent': 'List of arguments with argparse', 'rewritten_intent': \"add argument '-t' to argparse parser parser with dest 'table', help '' and nargs '+'\", 'id': '23490152_23490179_0'}\n",
      "{'question_id': 2721782, 'parent_answer_post_id': 2721807, 'prob': 0.8403723482242028, 'snippet': \"datetime.datetime.strptime(s, '%Y-%m-%dT%H:%M:%SZ')\", 'intent': 'How to convert a Date string to a DateTime object?', 'rewritten_intent': 'convert a date string s to a datetime object', 'id': '2721782_2721807_0'}\n",
      "{'question_id': 34155829, 'parent_answer_post_id': 34155926, 'prob': 0.837535791299236, 'snippet': 'np.array(x._data).reshape(x.size[::-1]).T', 'intent': 'How to efficiently convert Matlab engine arrays to numpy ndarray?', 'rewritten_intent': 'convert matlab engine array x to numpy ndarray', 'id': '34155829_34155926_0'}\n",
      "{'question_id': 14694482, 'parent_answer_post_id': 14694669, 'prob': 0.8237010308958093, 'snippet': \"soup.get_text().replace('\\\\n', '\\\\n\\\\n')\", 'intent': 'Converting html to text with Python', 'rewritten_intent': 'convert html string soup to text', 'id': '14694482_14694669_0'}\n",
      "{'question_id': 25474338, 'parent_answer_post_id': 25474443, 'prob': 0.8205543982410599, 'snippet': \"re.sub('(?<!\\\\\\\\S)((\\\\\\\\S+)(?:\\\\\\\\s+\\\\\\\\2))(?:\\\\\\\\s+\\\\\\\\2)+(?!\\\\\\\\S)', '\\\\\\\\1', s)\", 'intent': 'regex for repeating words in a string in Python', 'rewritten_intent': 'regex for repeating words in a string s', 'id': '25474338_25474443_0'}\n",
      "{'question_id': 861190, 'parent_answer_post_id': 861238, 'prob': 0.8154294381270654, 'snippet': \"mylist.sort(key=lambda d: (d['weight'], d['factor']))\", 'intent': 'Ordering a list of dictionaries in python', 'rewritten_intent': \"sort a list of dictionaries mylist by their values of key 'weight' and key 'factor'\", 'id': '861190_861238_0'}\n",
      "{'question_id': 33361446, 'parent_answer_post_id': 33361777, 'prob': 0.8129249178832164, 'snippet': 'itertools.combinations', 'intent': 'Two Combination Lists from One List', 'rewritten_intent': 'create a list of lists of lists of lists of lists', 'id': '33361446_33361777_1'}\n",
      "{'question_id': 35883459, 'parent_answer_post_id': 35883788, 'prob': 0.8094041284465692, 'snippet': \"[{'A': 1, 'C': 4, 'B': 2, 'D': 4}, {'A': 1, 'C': 4, 'B': 1, 'D': 5}]\", 'intent': 'Creating a list of dictionaries in python', 'rewritten_intent': \"create a list of dictionaries with keys 'A': 1, 'C': 4, 'B': 2, 'D': 4, 'A': 1, 'C': 4, 'B': 1, 'D': 5\", 'id': '35883459_35883788_0'}\n",
      "{'question_id': 4112265, 'parent_answer_post_id': 4112271, 'prob': 0.8087679282196032, 'snippet': 'zip(*[[1, 2], [3, 4], [5, 6]])', 'intent': 'How to zip lists in a list', 'rewritten_intent': 'zip lists [1, 2], [3, 4], [5, 6] in a list', 'id': '4112265_4112271_0'}\n",
      "{'question_id': 11390596, 'parent_answer_post_id': 11390788, 'prob': 0.8075025190109699, 'snippet': 'pygame.display.flip()', 'intent': 'How to display Image in pygame?', 'rewritten_intent': 'display image in pygame', 'id': '11390596_11390788_0'}\n",
      "{'question_id': 33361446, 'parent_answer_post_id': 33361777, 'prob': 0.8070727912859117, 'snippet': 'print([l[i:i + n] for i in range(len(l)) for n in range(1, len(l) - i + 1)])', 'intent': 'Two Combination Lists from One List', 'rewritten_intent': 'print a list of lists from list l', 'id': '33361446_33361777_0'}\n",
      "{'question_id': 31341468, 'parent_answer_post_id': 32243511, 'prob': 0.8017334357446445, 'snippet': \"Comment.objects.all().order_by('-hotness')\", 'intent': 'Dynamic order in django-mptt', 'rewritten_intent': \"order list of objects objects by '-hotness'\", 'id': '31341468_32243511_0'}\n",
      "{'question_id': 9880173, 'parent_answer_post_id': 9880400, 'prob': 0.801074958985297, 'snippet': \"urllib.parse.unquote('Foo%E2%84%A2%20Bar').decode('utf-8')\", 'intent': 'How to decode encodeURIComponent in GAE (python)?', 'rewritten_intent': \"decode encodeURIComponent 'Foo%E2%84%A2%20Bar' in GAE (python)\", 'id': '9880173_9880400_0'}\n",
      "{'question_id': 9775731, 'parent_answer_post_id': 9775761, 'prob': 0.7971271339774896, 'snippet': 'max(min(my_value, max_value), min_value)', 'intent': 'Clamping floating numbers in Python?', 'rewritten_intent': 'Clamp floating numbers in python', 'id': '9775731_9775761_0'}\n",
      "{'question_id': 38704545, 'parent_answer_post_id': 38704643, 'prob': 0.795089712837921, 'snippet': 'pd.get_dummies(df)', 'intent': 'How to binarize the values in a pandas DataFrame?', 'rewritten_intent': 'binarize the values in a pandas dataframe df', 'id': '38704545_38704643_0'}\n",
      "{'question_id': 15886340, 'parent_answer_post_id': 15886375, 'prob': 0.793709335659975, 'snippet': \"re.sub('[^A-Z]', '', s)\", 'intent': 'How to extract all UPPER from a string? Python', 'rewritten_intent': 'extract all uppercase letters from a string s', 'id': '15886340_15886375_0'}\n",
      "{'question_id': 587345, 'parent_answer_post_id': 587620, 'prob': 0.7926291652426495, 'snippet': \"re.compile('^(.+)\\\\\\\\n((?:\\\\\\\\n.+)+)', re.MULTILINE)\", 'intent': 'Python regular expression matching a multiline block of text', 'rewritten_intent': 'match a multiline block of text re', 'id': '587345_587620_0'}\n"
     ]
    }
   ],
   "source": [
    "# Load the CoNaLa dataset for code summarization\n",
    "dataset = load_dataset(\"codeparrot/conala-mined-curated\")\n",
    "\n",
    "print(dataset.column_names)\n",
    "# Print the first 5 instances from the dataset\n",
    "for i in range(20):\n",
    "    print(dataset['train'][i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
